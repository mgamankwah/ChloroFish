{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Shrimp dataframe creation\n","\n","This notebook creates a dataframe from the shrimp data called 'SHRIMP_unduplicated.csv', which will be used for modelling. No data cleaning or analysis will be done in this notebook, so there will be another notebook to process this csv file."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2795,"status":"ok","timestamp":1722989279133,"user":{"displayName":"Matthew Salinger","userId":"14047980405485722778"},"user_tz":240},"id":"QzeySlUAAzfn","outputId":"85e59461-3866-499d-99f4-fd9929d50f2e"},"outputs":[],"source":["# To use 'reduce', which iteratively applies a function to two elements of a time in a list.\n","from functools import reduce\n","\n","# Import necessary libraries\n","import pandas as pd"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31725,"status":"ok","timestamp":1722989617993,"user":{"displayName":"Matthew Salinger","userId":"14047980405485722778"},"user_tz":240},"id":"Yuiy-lzHBBly","outputId":"ef784b23-4e4e-4803-8e9c-92c665b61186"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_73374/4222207037.py:6: DtypeWarning: Columns (6,32) have mixed types. Specify dtype option on import or set low_memory=False.\n","  env_rec = pd.read_csv(file_path + 'ENVREC.csv')\n"]},{"name":"stdout","output_type":"stream","text":["len(env_rec) = 50752\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_73374/4222207037.py:10: DtypeWarning: Columns (6,16,32) have mixed types. Specify dtype option on import or set low_memory=False.\n","  sta_rec = pd.read_csv(file_path + 'STAREC.csv')\n"]},{"name":"stdout","output_type":"stream","text":["len(sta_rec) = 60802\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_73374/4222207037.py:14: DtypeWarning: Columns (11,12,13,26) have mixed types. Specify dtype option on import or set low_memory=False.\n","  inv_rec = pd.read_csv(file_path + 'INVREC.csv')\n"]},{"name":"stdout","output_type":"stream","text":["len(inv_rec) = 38245\n","len(ctd_rec) = 18270\n","len(shr_rec) = 11860\n"]}],"source":["## Loading relevant tables (tables that have STATIONID as a field)\n","\n","file_path = '../../data/SEAMAPDATAV3CSV/'\n","\n","#Environmental data at specific sample locations.\n","env_rec = pd.read_csv(file_path + 'ENVREC.csv')\n","print(f'len(env_rec) = {len(env_rec)}')\n","\n","# #Information on sampling locations during a survey.\n","sta_rec = pd.read_csv(file_path + 'STAREC.csv')\n","print(f'len(sta_rec) = {len(sta_rec)}')\n","\n","# #Total counts and weights of finfish, crustaceans and other organisms at specific sample locations.\n","inv_rec = pd.read_csv(file_path + 'INVREC.csv')\n","print(f'len(inv_rec) = {len(inv_rec)}')\n","\n","# #Count totals and weight totals of specific biological catch at a sample location.\n","#bgs_rec = pd.read_csv(file_path + 'BGSREC.csv')\n","#print(f'len(bgs_rec) = {len(bgs_rec)}')\n","\n","# #Location and times of CTD sample location.\n","ctd_rec = pd.read_csv(file_path + 'CTDREC.csv')\n","print(f'len(ctd_rec) = {len(ctd_rec)}')\n","\n","# #Shrimp records. Provides detailed information on pink, brown and white Shrimp.\n","shr_rec = pd.read_csv(file_path + 'SHRREC.csv')\n","print(f'len(shr_rec) = {len(shr_rec)}')\n","\n","# #Length frequency record for individual weights and lengths of the catch.\n","#glf_rec = pd.read_csv(file_path + 'GLFREC.csv')\n","#print(f'len(glf_rec) = {len(glf_rec)}')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180,"status":"ok","timestamp":1722989621526,"user":{"displayName":"Matthew Salinger","userId":"14047980405485722778"},"user_tz":240},"id":"mZ8fYA7RCKlC","outputId":"0d097f21-cfaa-4d7e-8e93-27924b17401b"},"outputs":[],"source":["# Selecting the relevant columns from env_rec, shr_rec, sta_rec, inv_rec\n","\n","\n","\n","\n","env_col = ['STATIONID',\n","                'DEPTH_EMAX', #Ocean depth\n","                'TEMPSURF', #Surface temperature\n","                'TEMPMID',  #Mid temperature\n","                'SALSURF',  #Surface salinity\n","                'SALMID',   #Mid depth salinity\n","                'SALMAX',   #Max depth salinity\n","                'OXYSURF',  #Surface oxygen\n","                'OXYMID',   #Mid depth oxygen\n","                'OXYMAX',   #Max depth oxygen\n","                'CHLORSURF',#Surface chlorophyll \n","                'CHLORMID', #Mid depth chlorophyll\n","                'CHLORMAX', #Max depth chlorophll\n","                'TURBSURF', #Surface turbidity\n","                'TURBMID',  #Mid depth turbidity\n","                'TURBMAX']  #Max depth turbidity\n","\n","\n","shr_col = ['STATIONID',\n","                'SAMPLE_BM', #Brown male shrimp weight\n","                'SAMPLE_BF', #Brown female shrimp weight\n","                'SAMPLE_PM', #Pink male shrimp weight\n","                'SAMPLE_PF', #Pink female shrimp weight\n","                'SAMPLE_WM', #White male shrimp weight\n","                'SAMPLE_WF', #White female shrimp weight\n","                'CNT_BM',    #Brown male shrimp count\n","                'CNT_BF',    #Brown female shrimp count\n","                'CNT_PM',    #Pink male shrimp count\n","                'CNT_PF',    #Pink female shrimp count\n","                'CNT_WM',    #White male shrimp count\n","                'CNT_WF']    #White female shrimp count\n","\n","inv_col = ['STATIONID',\n","        'GEAR_SIZE', # Net size\n","        'GEAR_TYPE', #Net type\n","        'MESH_SIZE', #Mesh of the net\n","        'MIN_FISH']  #Time fished\n","\n","sta_col = ['STATIONID',\n","           'CRUISEID',  #Cruise\n","           'FAUN_ZONE', #Fauna zone\n","           'STAT_ZONE', #Shrimp statistical zone\n","           'TEMP_SSURF',#Surf temperature\n","           'TEMP_BOT',  #Bottom temperature\n","           'TEMP_SAIR', #Air temperature\n","           'HAULVALUE',\n","           'TIME_MIL',  #Military time\n","           'DECSLAT',   #Starting latitude\n","            'DECSLON',  #Starting longitude\n","            'DECELAT',  #Ending latitude\n","            'DECELON',  #Ending longitude\n","            'MO_DAY_YR', #MM/DD/YYYY format\n","            'WAVE_HT']  #Wave height\n","\n","\n","#Making smaller data frames\n","\n","inv_df = inv_rec[inv_col]\n","sta_df = sta_rec[sta_col]\n","env_df = env_rec[env_col]\n","shr_df = shr_rec[shr_col]\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1722989626871,"user":{"displayName":"Matthew Salinger","userId":"14047980405485722778"},"user_tz":240},"id":"pbNl0g9jCLDh","outputId":"2e7e63ed-d9b3-43d4-cb56-976a1e9de9e4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_73374/3608406339.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sta_df['MO_DAY_YR'] = pd.to_datetime(sta_df['MO_DAY_YR'], format='%d/%m/%Y')\n","/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_73374/3608406339.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sta_df['YEAR'] = sta_df['MO_DAY_YR'].dt.year\n","/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_73374/3608406339.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sta_df['DAYOFYEAR'] = sta_df['MO_DAY_YR'].dt.dayofyear\n"]}],"source":["\n","# Convert the 'MO_DAY_YR' column to datetime\n","sta_df['MO_DAY_YR'] = pd.to_datetime(sta_df['MO_DAY_YR'], format='%d/%m/%Y')\n","\n","# Extract the year and day of the year\n","sta_df['YEAR'] = sta_df['MO_DAY_YR'].dt.year\n","sta_df['DAYOFYEAR'] = sta_df['MO_DAY_YR'].dt.dayofyear\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178,"status":"ok","timestamp":1722989635295,"user":{"displayName":"Matthew Salinger","userId":"14047980405485722778"},"user_tz":240},"id":"Aww88e8TCYHB","outputId":"4452702f-d1db-4513-dc2d-67fc24ee3390"},"outputs":[{"data":{"text/plain":["10646"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#Joining the four data frames\n","\n","main_frames = [env_df, sta_df, shr_df,inv_df]\n","df0 = reduce(lambda  left,right: pd.merge(left, right, on='STATIONID', how='inner'), main_frames)\n","len(df0)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":181,"status":"ok","timestamp":1722989659590,"user":{"displayName":"Matthew Salinger","userId":"14047980405485722778"},"user_tz":240},"id":"jsdAjnyGCfs5"},"outputs":[],"source":["#Finding duplicate STATIONID\n","#Since each STATIONID corresponds to a trawl, these should be unique\n","\n","stations = dict()\n","\n","for id in df0['STATIONID']:\n","    if id not in stations:\n","        stations[id] = 1\n","    else:\n","        stations[id] += 1"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1722989661804,"user":{"displayName":"Matthew Salinger","userId":"14047980405485722778"},"user_tz":240},"id":"ACgQtJIXCfvK","outputId":"cfd2dd99-6f47-441e-9f4f-502aba052c39"},"outputs":[{"name":"stdout","output_type":"stream","text":["208495 2\n","218424 2\n","218433 2\n","226027 2\n","226077 2\n","226127 2\n","226106 2\n","226928 2\n","226988 2\n","227305 2\n","227372 2\n","227397 2\n","227406 2\n","227477 2\n","229410 2\n","229409 2\n","229438 2\n","229484 2\n","229499 2\n","229502 2\n","229520 2\n","235274 2\n","235285 2\n"]}],"source":["for key in stations.keys():\n","    if stations[key] > 1:\n","        print(key, stations[key])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"HnfOWuLsCfyl"},"outputs":[{"name":"stdout","output_type":"stream","text":["Rows with duplicated STATIONID values:\n","       ENVRECID  CRUISEID  STATIONID  VESSEL  CRUISE_NO  P_STA_NO CLD_TYPE  \\\n","29993     63007       742     105875       4        270        97      NaN   \n","29998     63012       742     105875       4        270        97      NaN   \n","30396     63515       746     106594       4        275       158      NaN   \n","30397     63516       746     106594       4        275       158      NaN   \n","32273     88689       767     140465      63         91         1      NaN   \n","...         ...       ...        ...     ...        ...       ...      ...   \n","50268    167244      1129     234751       4        346        71      NaN   \n","50420    167546      1136     235274       4        348        56      NaN   \n","50421    167547      1136     235274       4        348        56      NaN   \n","50432    167558      1136     235285       4        348        67      NaN   \n","50433    167559      1136     235285       4        348        67      NaN   \n","\n","       CLD_COVER  SECCHI_DSK  WECOLOR  ... OXYMID  OXYMAX  TURBSURF  TURBMID  \\\n","29993       50.0        36.0      0.0  ...    7.0     6.0       NaN      NaN   \n","29998        NaN         NaN      NaN  ...    NaN     NaN       NaN      NaN   \n","30396       30.0         NaN      0.0  ...    6.4     5.5       NaN      NaN   \n","30397        NaN         NaN      NaN  ...    NaN     NaN       NaN      NaN   \n","32273        NaN         NaN      NaN  ...    4.0     4.0       NaN      NaN   \n","...          ...         ...      ...  ...    ...     ...       ...      ...   \n","50268        NaN         NaN      NaN  ...    6.2     6.2       NaN      NaN   \n","50420       75.0         NaN      0.0  ...    6.5     5.5       NaN      NaN   \n","50421        NaN         NaN      NaN  ...    6.6     5.4       NaN      NaN   \n","50432       75.0         NaN      0.0  ...    4.8     3.2       NaN      NaN   \n","50433        NaN         NaN      NaN  ...    4.5     3.7       NaN      NaN   \n","\n","       TURBMAX                                             COMENV  CTDFILE  \\\n","29993      NaN                                                NaN      NaN   \n","29998      NaN                                                NaN      NaN   \n","30396      NaN                                                NaN      NaN   \n","30397      NaN                                                NaN      NaN   \n","32273      NaN  2ND ATTEMPT ASCII OVERFLOW NOT TURNED OFF MESS...      NaN   \n","...        ...                                                ...      ...   \n","50268      NaN  ENV LAT/LON from CTD postion. EVT_OP=Andy Mill...      NaN   \n","50420      NaN  ENV LAT/LON from CTD postion. EVT_OP=Taniya Wa...      NaN   \n","50421      NaN  ENV LAT/LON from CTD postion. EVT_OP=Taniya Wa...      NaN   \n","50432      NaN  ENV LAT/LON from CTD postion. EVT_OP=Adam Poll...      NaN   \n","50433      NaN  ENV LAT/LON from CTD postion. EVT_OP=Adam Poll...      NaN   \n","\n","       LIGHT_CODE  LATITUDE  LONGITUDE  \n","29993         NaN       NaN        NaN  \n","29998         NaN       NaN        NaN  \n","30396         NaN       NaN        NaN  \n","30397         NaN       NaN        NaN  \n","32273         NaN       NaN        NaN  \n","...           ...       ...        ...  \n","50268         NaN    29.230    -93.434  \n","50420         NaN    28.344    -92.939  \n","50421         NaN    28.348    -92.930  \n","50432         NaN    29.011    -91.813  \n","50433         NaN    28.987    -91.790  \n","\n","[94 rows x 36 columns]\n"]}],"source":["#Examining the duplication STATIONID\n","duplicated_rows_env = env_rec[env_rec.duplicated(subset='STATIONID', keep=False)]\n","\n","print(\"Rows with duplicated STATIONID values:\")\n","print(duplicated_rows_env)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#Since there are relatively few duplicates, we will just drop them\n","# Identify duplicated 'STATIONID'\n","duplicated_mask = df0['STATIONID'].duplicated(keep=False)\n","\n","# Filter out rows where 'STATIONID' is duplicated\n","df_no_duplicates = df0[~duplicated_mask]\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["#Writing the datafram without duplicates to a CSV\n","df_no_duplicates.to_csv('../../data/SHRIMP_unduplicated.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
